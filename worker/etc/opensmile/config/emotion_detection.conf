[componentInstances:cComponentManager]
 // this line configures the default data memory:
instance[dataMemory].type=cDataMemory

 ////// Enable this, to dump the detected turns as wave files
;instance[turnOutp].type=cWaveSinkCut

instance[dbg].type = cExampleSink

instance[emotionSender].type=cEmoSender
instance[userinfoSender].type=cEmoSender

 // set printLevelStats=5 to see the feature names in each level for debugging problems with the feature config
printLevelStats=0
nThreads=1
execDebug=0

[emotionSender:cEmoSender]
dummy = 0

[userinfoSender:cEmoSender]
dummy = 0

[dbg:cExampleSink]
reader.dmLevel = functOnsets_EMO

#### Audio input (look at this file to change the audio sample-rate and sound device, etc.)
;\{audio_in.conf}
\{wave_in.conf}

#### Prosodic features (pitch, energy, pitch accent)
\{prosody.conf}

#### senders / receivers
;\{senders.conf}

//////// better LSTM based VAD (faster, more responsive)
\{activity_detection.conf}

///////// The computationally complex emotion configuration: ( Set A )
\{emotion_features.conf}
;; This file loads the smaller models (created with CFS feature selection)
\{emotion_classifiers.conf}

\{interest_classifier.conf}

;;; debug outputs
[turnOutp:cWaveSinkCut]
preSil=0.5
reader.dmLevel = fr25